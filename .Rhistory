#df$Preparation_Date <- ifelse(df$Preparation_Date >= 60, df$Preparation_Date - 1, df$Preparation_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Preparation_Date <- as.Date(df$Preparation_Date, origin = "1904-01-01")  # Correct origin
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Preparation_Date <- as.Date(df$Preparation_Date, format = "%m/%d/%y")  # Parse date
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Analysis_Date column
# df$Analysis_Date <- as.character(df$Analysis_Date)  # Ensure it's a character
# Check if Analysis_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Analysis_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Analysis_Date <- as.numeric(df$Analysis_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Analysis_Date <- ifelse(df$Analysis_Date >= 60, df$Analysis_Date - 1, df$Analysis_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Analysis_Date <- as.Date(df$Analysis_Date, origin = "1904-01-01")  # Correct origin
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Analysis_Date <- as.Date(df$Analysis_Date, format = "%m/%d/%y")  # Parse date
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Activity_Start_Date column
# df$Activity_Start_Date <- as.character(df$Activity_Start_Date)  # Ensure it's a character
# Check if Activity_Start_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Activity_Start_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Activity_Start_Date <- as.numeric(df$Activity_Start_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Activity_Start_Date <- ifelse(df$Activity_Start_Date >= 60, df$Activity_Start_Date - 1, df$Activity_Start_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, origin = "1904-01-01")  # Correct origin
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, format = "%m/%d/%y")  # Parse date
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Round Abs and Result_Value to proper decimal places
df$'Abs' <- as.numeric(df$'Abs')
df$'Abs' <- round(df$'Abs', 5)
df$'Result_Value(ug/L)' <- as.numeric(df$'Result_Value(ug/L)')
df$'Result_Value(ug/L)' <- round(df$'Result_Value(ug/L)', 0)
return(df)
}
# Read and combine all valid files
combined_data <- file_list %>%
map_df(read_as_text)
write.table(combined_data, file = "Data/Project Coast/TP_STACKED.csv", sep = ",", na = "", row.names = FALSE, quote = FALSE)
# Project Notes ----
#Future Directions - mash up all the stacked file creation codes with this one to run all together
#Time formats are solved in stacked file creation codes but dates are solved here.
#Before running this code:
#use the script for Stacked File Creation
#Change column names to match code - use template in project folder
#Change output file names to new upload month
#Sampling Agency Names : University of Florida (Soil and Water Sciences Department)
#Project ID: 21FLUFSW
### WD and Packages ----
setwd("~/Documents/GitHub/WIN File Creation")
library(tidyverse)
library(readxl)
library(dplyr)
library(readr)
library(lubridate)
library(purrr)
### Data Import ----
TP <- read_csv("Data/Project Coast/TP_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
))
TN <- read_csv("Data/Project Coast/TN_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
))
CHL <- read_csv("Data/Project Coast/CHL_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
Station = col_character()
))
Secchi <- read_csv("Data/Project Coast/Secchi_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
Activity_Start_Time = col_character(),
))
### Functions ----
#Can these be mutates?
#Work on this one for LW too
# If value qualifier = S, then total Depth needs to = org result value.
# mutate_columns <- function(Secchi, S, Value_Qualifier, Total_Depth, Org_Result_Value) {
#   Secchi[[Total_Depth]][Secchi[[Value_Qualifier]] == "S"] <- Secchi[[Org_Result_Value]][Secchi[[Value_Qualifier]] == "S"]
#   return(Secchi)
# }
#For blank org result value, org result value should = "Not Reported".
# not_reported_secchi <- function(Org_Result_Value){
#   ifelse(is.na(Org_Result_Value), "Not Reported", Org_Result_Value)
#   }
### SECCHI ----
#Change format of times
# v1<- c(Secchi$Activity_Start_Time)
# x <- lubridate::parse_date_time(v1,'H:M:S')
# format(x, format = '%I:%M:%S %p')
#change format of dates
v2<- c(Secchi$Activity_Start_Date)
x2 <- lubridate::parse_date_time(v2,'"%m%d%y"')
format(x2, format = '%m/%d/%Y')
Secchi_t <- Secchi%>%
# mutate('Activity_Start_Time'=format(x, format = '%I:%M:%S %p')) %>%
mutate('Activity_Start_Date'=format(x2, format = '%m/%d/%Y')) %>%
# mutate('Total Depth' = mutate_columns(Secchi, "Value_Qualifier", "Total_Depth", "Org_Result_Value")) %>%
# mutate(Org_Result_Value = not_reported_secchi(Org_Result_Value)) %>%
mutate(Org_Analyte_Name = "Depth, Secchi Disk Depth")
#change columns
#Secchi_t <- rename(Secchi_t, Site = Lake)
#Add columns
Secchi_WIN <- Secchi_t
Secchi_WIN$Project_ID <- "21FLUFSW"
Secchi_WIN$Sampling_Agency_Name <- "University of Florida (Soil and Water Sciences Department)"
Secchi_WIN$Matrix <- "AQUEOUS-Surface Water"
Secchi_WIN$Monitoring_Location_ID = paste0(Secchi$Site,"-",Secchi$Station)
Secchi_WIN$Activity_ID = paste0(Secchi_WIN$Monitoring_Location_ID,"-",Secchi_t$Activity_Start_Date,"F")
Secchi_WIN$Activity_Date_Time = paste0(Secchi_t$Activity_Start_Date," ",Secchi_t$Activity_Start_Time)
Secchi_WIN$Preparation_Date_Time = paste0(" ")
Secchi_WIN$Analysis_Date_Time = paste0(" ")
Secchi_WIN$Lab_ID = paste("21FLKWAT")
Secchi_WIN$Lab_Accreditation_Authority = paste("None")
Secchi_WIN$Lab_Sample_ID = paste0(Secchi_WIN$Activity_ID)
#Reorder columns
Secchi_Print <- Secchi_WIN[,c("Project_ID","Sampling_Agency_Name","Matrix",
"Monitoring_Location_ID","Activity_ID","ADAPT_Analyte_ID","Org_Analyte_Name",
"Activity_Type","Sample_Collection_Type","Sample_Collection_Equipment",
"Activity_Depth","Activity_Depth_Unit","Total_Depth",
"Total_Depth_Unit","Analysis_Method","Sample_Fraction",
"Preparation_Date_Time","Preparation_Time_Zone","Analysis_Date_Time",
"Analysis_Time_Zone","Activity_Date_Time","Activity_Time_Zone",
"Org_Result_Value","Org_Result_Unit","Org_MDL",
"Org_PQL","Org_Detection_Unit","Value_Qualifier",
"Result_Comments","Result_Value_Type_Name","Dilution",
"Lab_ID","Lab_Accreditation_Authority","Lab_Sample_ID")]
#Subset Secchi Start Time for join with TN TP
Secchi_Join <- Secchi_t[,c("County", "Site", "Activity_Start_Date", "Activity_Start_Time", "Station", "Activity_Time_Zone")]
#make station character to join with others
Secchi_Join$Station <- as.character(Secchi_Join$Station)
##Change date to avoid overwriting older files##
write.table(Secchi_Print, file = "Output/Secchi_Feb2025.txt", sep = "|", na = "", row.names = FALSE, quote = FALSE)
### TP ----
#Change format of times
# v3 <- c(TP$Analysis_Time)
# x3 <- lubridate::parse_date_time(v3,'H:M:S')
# format(x3, format = '%I:%M:%S %p')
#Change format of times
# v4<- c(TP$Preparation_Time)
# x4 <- lubridate::parse_date_time(v4,'H:M:S')
# format(x4, format = '%I:%M:%S %p')
#change format of dates
v5<- c(TP$Activity_Start_Date)
x5 <- lubridate::parse_date_time(v5,'"%m%d%y"')
format(x5, format = '%m/%d/%Y')
v105<- c(TP$Preparation_Date)
x105 <- lubridate::parse_date_time(v105,'"%m%d%y"')
format(x105, format = '%m/%d/%Y')
v106<- c(TP$Analysis_Date)
x106 <- lubridate::parse_date_time(v106,'"%m%d%y"')
format(x106, format = '%m/%d/%Y')
TP_t = TP%>%
mutate('Activity_Start_Date'=format(x5, format = '%m/%d/%Y')) %>%
mutate('Preparation_Date'=format(x105, format = '%m/%d/%Y')) %>%
mutate('Analysis_Date'=format(x106, format = '%m/%d/%Y')) %>%
# mutate('Analysis_Time'=format(x2, format = '%I:%M:%S %p'))%>%
# mutate('Preparation_Time'=format(x3, format = '%I:%M:%S %p'))%>%
mutate('WIN_Value_Qualifier' = ifelse(WIN_Value_Qualifier %in% c("T", "TI"), "U",
ifelse(WIN_Value_Qualifier == "QTI", "QU", WIN_Value_Qualifier)))
### Project Notes ----
#Before running, change file path at start and end of code (month)
#This script is for making a stacked file for use in Project Coast File Creation Code
#this is still writing dates YY not YYYY - can't solve here - fixed in Creation code
### WD and Packages ----
library(readxl) # For reading Excel files
library(dplyr) # For data manipulation
library(purrr) # For functional programming (map functions)
library(lubridate) # For date-time manipulation
### Read in Data ----
folder_path <- "/Users/mevanskeene/Desktop/Project Coast/Coast Data February 2025/Data/TN"
# Exclude temp files (~$) and select .xlsm files
file_list <- list.files(
path = folder_path,
pattern = "^[^~].*\\.xlsm$",
full.names = TRUE
)
# Function to read an Excel sheet with all columns as text
read_as_text <- function(file) {
col_names <- read_excel(file, sheet = "Nitrogen-Total", n_max = 1) %>% names()
# Read the entire sheet with all columns as text
df <- read_excel(file, sheet = "Nitrogen-Total", col_types = rep("text", length(col_names)))
# Convert the prep time column
df$Preparation_Time <- as.character(df$Preparation_Time)  # Ensure time is a character
df <- df %>%
mutate(Result_Comments = trimws(as.character(Result_Comments))) %>%  # Ensure clean character values
filter(Result_Comments != "Redo" | is.na(Result_Comments))  %>%
filter(Result_Comments != "Rerun" | is.na(Result_Comments))
# If time is stored as numeric (fraction of a day), convert it back to time format
if(any(grepl("^[0-9.]+$", df$Preparation_Time))) {  # Check if the column has numbers
df$Preparation_Time <- as.numeric(df$Preparation_Time) * 86400  # Convert to seconds
df$Preparation_Time <- format(as.POSIXct(df$Preparation_Time, origin = "1970-01-01", tz = "UTC"), "%I:%M:%S %p")
}
# Convert the analysis time column
df$Analysis_Time <- as.character(df$Analysis_Time)  # Ensure time is a character
# If time is stored as numeric (fraction of a day), convert it back to time format
if(any(grepl("^[0-9.]+$", df$Analysis_Time))) {  # Check if the column has numbers
df$Analysis_Time <- as.numeric(df$Analysis_Time) * 86400  # Convert to seconds
df$Analysis_Time <- format(as.POSIXct(df$Analysis_Time, origin = "1970-01-01", tz = "UTC"), "%I:%M:%S %p")
}
# Handle the Preparation_Date column
# df$Preparation_Date <- as.character(df$Preparation_Date)  # Ensure it's a character
# Check if Preparation_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Preparation_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Preparation_Date <- as.numeric(df$Preparation_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Preparation_Date <- ifelse(df$Preparation_Date >= 60, df$Preparation_Date - 1, df$Preparation_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Preparation_Date <- as.Date(df$Preparation_Date, origin = "1904-01-01")  # Correct origin
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Preparation_Date <- as.Date(df$Preparation_Date, format = "%m/%d/%y")  # Parse date
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Analysis_Date column
# df$Analysis_Date <- as.character(df$Analysis_Date)  # Ensure it's a character
# Check if Analysis_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Analysis_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Analysis_Date <- as.numeric(df$Analysis_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Analysis_Date <- ifelse(df$Analysis_Date >= 60, df$Analysis_Date - 1, df$Analysis_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Analysis_Date <- as.Date(df$Analysis_Date, origin = "1904-01-01")  # Correct origin
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Analysis_Date <- as.Date(df$Analysis_Date, format = "%m/%d/%y")  # Parse date
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Activity_Start_Date column
# df$Activity_Start_Date <- as.character(df$Activity_Start_Date)  # Ensure it's a character
# Check if Activity_Start_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Activity_Start_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Activity_Start_Date <- as.numeric(df$Activity_Start_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Activity_Start_Date <- ifelse(df$Activity_Start_Date >= 60, df$Activity_Start_Date - 1, df$Activity_Start_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, origin = "1904-01-01")  # Correct origin
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, format = "%m/%d/%y")  # Parse date
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Round Abs and Result_Value to proper decimal places
df$'Abs' <- as.numeric(df$'Abs')
df$'Abs' <- round(df$'Abs', 5)
df$'Result_Value(ug/L)' <- as.numeric(df$'Result_Value(ug/L)')
df$'Result_Value(ug/L)' <- round(df$'Result_Value(ug/L)', 0)
return(df)
}
# Read and combine all valid files
combined_data <- file_list %>%
map_df(read_as_text)
write.table(combined_data, file = "Data/Project Coast/TN_STACKED.csv", sep = ",", na = "", row.names = FALSE, quote = FALSE)
### Project Notes ----
#Before running, change file path at start and end of code
#This script is for making a stacked file for use in Project Coast File Creation Code
#this is still writing dates YY not YYYY - can't solve here - fixed in Creation code
### WD and Packages ----
library(readxl) # For reading Excel files
library(dplyr) # For data manipulation
library(purrr) # For functional programming (map functions)
library(lubridate) # For date-time manipulation
### Read in Data ----
folder_path <- "/Users/mevanskeene/Desktop/Project Coast/Coast Data February 2025/Data/TP"
# Exclude temp files (~$) and select .xlsm files
file_list <- list.files(
path = folder_path,
pattern = "^[^~].*\\.xlsm$",
full.names = TRUE
)
# Function to read an Excel sheet with all columns as text
read_as_text <- function(file) {
col_names <- read_excel(file, sheet = "Phosphorus-Total", n_max = 1) %>% names()
# Read the entire sheet with all columns as text
df <- read_excel(file, sheet = "Phosphorus-Total", col_types = rep("text", length(col_names)))
# Convert the prep time column
df$Preparation_Time <- as.character(df$Preparation_Time) # Ensure time is a character
df <- df %>%
mutate(Result_Comments = trimws(as.character(Result_Comments))) %>%  # Ensure clean character values
filter(Result_Comments != "Redo" | is.na(Result_Comments))  # Keep NAs
# If time is stored as numeric (fraction of a day), convert it back to time format
if(any(grepl("^[0-9.]+$", df$Preparation_Time))) {  # Check if the column has numbers
df$Preparation_Time <- as.numeric(df$Preparation_Time) * 86400  # Convert to seconds
df$Preparation_Time <- format(as.POSIXct(df$Preparation_Time, origin = "1970-01-01", tz = "UTC"), "%I:%M:%S %p")
}
# Convert the analysis time column
df$Analysis_Time <- as.character(df$Analysis_Time)  # Ensure time is a character
# If time is stored as numeric (fraction of a day), convert it back to time format
if(any(grepl("^[0-9.]+$", df$Analysis_Time))) {  # Check if the column has numbers
df$Analysis_Time <- as.numeric(df$Analysis_Time) * 86400  # Convert to seconds
df$Analysis_Time <- format(as.POSIXct(df$Analysis_Time, origin = "1970-01-01", tz = "UTC"), "%I:%M:%S %p")
}
# Handle the Preparation_Date column
# df$Preparation_Date <- as.character(df$Preparation_Date)  # Ensure it's a character
# Check if Preparation_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Preparation_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Preparation_Date <- as.numeric(df$Preparation_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug. THis was returning dates that were 4 years early, hence the 1904
#df$Preparation_Date <- ifelse(df$Preparation_Date >= 60, df$Preparation_Date - 1, df$Preparation_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Preparation_Date <- as.Date(df$Preparation_Date, origin = "1904-01-01")  # Correct origin
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Preparation_Date <- as.Date(df$Preparation_Date, format = "%m/%d/%y")  # Parse date
df$Preparation_Date <- format(df$Preparation_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Analysis_Date column
# df$Analysis_Date <- as.character(df$Analysis_Date)  # Ensure it's a character
# Check if Analysis_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Analysis_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Analysis_Date <- as.numeric(df$Analysis_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Analysis_Date <- ifelse(df$Analysis_Date >= 60, df$Analysis_Date - 1, df$Analysis_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Analysis_Date <- as.Date(df$Analysis_Date, origin = "1904-01-01")  # Correct origin
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Analysis_Date <- as.Date(df$Analysis_Date, format = "%m/%d/%y")  # Parse date
df$Analysis_Date <- format(df$Analysis_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Handle the Activity_Start_Date column
# df$Activity_Start_Date <- as.character(df$Activity_Start_Date)  # Ensure it's a character
# Check if Activity_Start_Date is numeric (Excel serial date)
if (any(grepl("^[0-9.]+$", df$Activity_Start_Date))) {
# Convert numeric Excel serial date to Date, correcting the 1900 leap year bug
df$Activity_Start_Date <- as.numeric(df$Activity_Start_Date)
# Excel serial number conversion: If it's greater than or equal to 60, we subtract 1 day due to the leap year bug.
#df$Activity_Start_Date <- ifelse(df$Activity_Start_Date >= 60, df$Activity_Start_Date - 1, df$Activity_Start_Date)
# Convert serial date to Date, applying the correct origin (1904-01-01)
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, origin = "1904-01-01")  # Correct origin
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
} else {
# If it's a text-based date, assume it is in 'MM/DD/YY' format and reformat it
df$Activity_Start_Date <- as.Date(df$Activity_Start_Date, format = "%m/%d/%y")  # Parse date
df$Activity_Start_Date <- format(df$Activity_Start_Date, "%m/%d/%Y")  # Format as MM/DD/YYYY
}
# Round Abs and Result_Value to proper decimal places
df$'Abs' <- as.numeric(df$'Abs')
df$'Abs' <- round(df$'Abs', 5)
df$'Result_Value(ug/L)' <- as.numeric(df$'Result_Value(ug/L)')
df$'Result_Value(ug/L)' <- round(df$'Result_Value(ug/L)', 0)
return(df)
}
# Read and combine all valid files
combined_data <- file_list %>%
map_df(read_as_text)
write.table(combined_data, file = "Data/Project Coast/TP_STACKED.csv", sep = ",", na = "", row.names = FALSE, quote = FALSE)
# Project Notes ----
#Future Directions - mash up all the stacked file creation codes with this one to run all together
#Time formats are solved in stacked file creation codes but dates are solved here.
#Before running this code:
#use the script for Stacked File Creation
#Change column names to match code - use template in project folder
#Change output file names to new upload month
#Sampling Agency Names : University of Florida (Soil and Water Sciences Department)
#Project ID: 21FLUFSW
### WD and Packages ----
setwd("~/Documents/GitHub/WIN File Creation")
library(tidyverse)
library(readxl)
library(dplyr)
library(readr)
library(lubridate)
library(purrr)
### Data Import ----
TP <- read_csv("Data/Project Coast/TP_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
))
TN <- read_csv("Data/Project Coast/TN_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
))
CHL <- read_csv("Data/Project Coast/CHL_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
Station = col_character()
))
Secchi <- read_csv("Data/Project Coast/Secchi_STACKED.csv", col_types = cols(
Preparation_Time = col_character(),
Analysis_Time = col_character(),
Activity_Start_Time = col_character(),
))
### Functions ----
#Can these be mutates?
#Work on this one for LW too
# If value qualifier = S, then total Depth needs to = org result value.
# mutate_columns <- function(Secchi, S, Value_Qualifier, Total_Depth, Org_Result_Value) {
#   Secchi[[Total_Depth]][Secchi[[Value_Qualifier]] == "S"] <- Secchi[[Org_Result_Value]][Secchi[[Value_Qualifier]] == "S"]
#   return(Secchi)
# }
#For blank org result value, org result value should = "Not Reported".
# not_reported_secchi <- function(Org_Result_Value){
#   ifelse(is.na(Org_Result_Value), "Not Reported", Org_Result_Value)
#   }
### SECCHI ----
#Change format of times
# v1<- c(Secchi$Activity_Start_Time)
# x <- lubridate::parse_date_time(v1,'H:M:S')
# format(x, format = '%I:%M:%S %p')
#change format of dates
v2<- c(Secchi$Activity_Start_Date)
x2 <- lubridate::parse_date_time(v2,'"%m%d%y"')
format(x2, format = '%m/%d/%Y')
Secchi_t <- Secchi%>%
# mutate('Activity_Start_Time'=format(x, format = '%I:%M:%S %p')) %>%
mutate('Activity_Start_Date'=format(x2, format = '%m/%d/%Y')) %>%
# mutate('Total Depth' = mutate_columns(Secchi, "Value_Qualifier", "Total_Depth", "Org_Result_Value")) %>%
# mutate(Org_Result_Value = not_reported_secchi(Org_Result_Value)) %>%
mutate(Org_Analyte_Name = "Depth, Secchi Disk Depth")
#change columns
#Secchi_t <- rename(Secchi_t, Site = Lake)
#Add columns
Secchi_WIN <- Secchi_t
Secchi_WIN$Project_ID <- "21FLUFSW"
Secchi_WIN$Sampling_Agency_Name <- "University of Florida (Soil and Water Sciences Department)"
Secchi_WIN$Matrix <- "AQUEOUS-Surface Water"
Secchi_WIN$Monitoring_Location_ID = paste0(Secchi$Site,"-",Secchi$Station)
Secchi_WIN$Activity_ID = paste0(Secchi_WIN$Monitoring_Location_ID,"-",Secchi_t$Activity_Start_Date,"F")
Secchi_WIN$Activity_Date_Time = paste0(Secchi_t$Activity_Start_Date," ",Secchi_t$Activity_Start_Time)
Secchi_WIN$Preparation_Date_Time = paste0(" ")
Secchi_WIN$Analysis_Date_Time = paste0(" ")
Secchi_WIN$Lab_ID = paste("21FLKWAT")
Secchi_WIN$Lab_Accreditation_Authority = paste("None")
Secchi_WIN$Lab_Sample_ID = paste0(Secchi_WIN$Activity_ID)
#Reorder columns
Secchi_Print <- Secchi_WIN[,c("Project_ID","Sampling_Agency_Name","Matrix",
"Monitoring_Location_ID","Activity_ID","ADAPT_Analyte_ID","Org_Analyte_Name",
"Activity_Type","Sample_Collection_Type","Sample_Collection_Equipment",
"Activity_Depth","Activity_Depth_Unit","Total_Depth",
"Total_Depth_Unit","Analysis_Method","Sample_Fraction",
"Preparation_Date_Time","Preparation_Time_Zone","Analysis_Date_Time",
"Analysis_Time_Zone","Activity_Date_Time","Activity_Time_Zone",
"Org_Result_Value","Org_Result_Unit","Org_MDL",
"Org_PQL","Org_Detection_Unit","Value_Qualifier",
"Result_Comments","Result_Value_Type_Name","Dilution",
"Lab_ID","Lab_Accreditation_Authority","Lab_Sample_ID")]
#Subset Secchi Start Time for join with TN TP
Secchi_Join <- Secchi_t[,c("County", "Site", "Activity_Start_Date", "Activity_Start_Time", "Station", "Activity_Time_Zone")]
#make station character to join with others
Secchi_Join$Station <- as.character(Secchi_Join$Station)
##Change date to avoid overwriting older files##
write.table(Secchi_Print, file = "Output/Secchi_Feb2025.txt", sep = "|", na = "", row.names = FALSE, quote = FALSE)
### TP ----
#Change format of times
# v3 <- c(TP$Analysis_Time)
# x3 <- lubridate::parse_date_time(v3,'H:M:S')
# format(x3, format = '%I:%M:%S %p')
#Change format of times
# v4<- c(TP$Preparation_Time)
# x4 <- lubridate::parse_date_time(v4,'H:M:S')
# format(x4, format = '%I:%M:%S %p')
#change format of dates
v5<- c(TP$Activity_Start_Date)
x5 <- lubridate::parse_date_time(v5,'"%m%d%y"')
format(x5, format = '%m/%d/%Y')
v105<- c(TP$Preparation_Date)
x105 <- lubridate::parse_date_time(v105,'"%m%d%y"')
format(x105, format = '%m/%d/%Y')
v106<- c(TP$Analysis_Date)
x106 <- lubridate::parse_date_time(v106,'"%m%d%y"')
format(x106, format = '%m/%d/%Y')
TP_t = TP%>%
mutate('Activity_Start_Date'=format(x5, format = '%m/%d/%Y')) %>%
mutate('Preparation_Date'=format(x105, format = '%m/%d/%Y')) %>%
mutate('Analysis_Date'=format(x106, format = '%m/%d/%Y')) %>%
# mutate('Analysis_Time'=format(x2, format = '%I:%M:%S %p'))%>%
# mutate('Preparation_Time'=format(x3, format = '%I:%M:%S %p'))%>%
mutate('WIN_Value_Qualifier' = ifelse(WIN_Value_Qualifier %in% c("T", "TI"), "U",
ifelse(WIN_Value_Qualifier == "QTI", "QU", WIN_Value_Qualifier)))
#mutate('Result_Value(ug/L)' = ifelse('Result_Value(ug/L)' <6, 6, 'Result_Value(ug/L)'))
#change columns
TP_t <- rename(TP_t, Site = Lake)
#filter out rows that are not stations "1"-"10" and sites that are not Project Coast
TP_t <- TP_t %>%
filter(Station %in% c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))%>%
filter(Site %in% c("CIT-CRY", "CIT-HOM", "CIT-WIT", "HER-CHA", "HER-WEE", "PAS-ANC", "PAS-ARI", "PAS-HUD", "PAS-PIT"))
#join with Secchi for start time
TP_Time = full_join(TP_t, Secchi_Join,
by = c("County", "Site", "Activity_Start_Date", "Station"))
#Add columns (rearrange these to match final file for ease of error fixing later)
TP_WIN <- TP_Time
TP_WIN$Project_ID <- "21FLUFSW"
TP_WIN$Sampling_Agency_Name <- "University of Florida (Soil and Water Sciences Department)"
TP_WIN$Matrix <- "AQUEOUS-Surface Water"
TP_WIN$Monitoring_Location_ID = paste0(TP_t$Site,"-",TP_t$Station)
View(TP_Time)
